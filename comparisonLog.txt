This log file was generated at 17:27:27, on 01/04/2025.

ACCURACY RESULTS:
Dataset:  Worst     Poor      OK        Good      Best      
Current:  0.7667    0.9333    0.9667    1         1         
Original: 0.79      0.91666   0.94668   0.9967    1         

CONFIDENCE RESULTS:
Dataset:  Worst     Poor      OK        Good      Best      
Current:  0.74664   0.92295   0.92132   0.97891   0.98334   
Original: 0.71739   0.88556   0.91899   0.97239   0.98774   

CORRECT CONFIDENCE RESULTS:
Dataset:  Worst     Poor      OK        Good      Best      
Current:  0.89321   0.96647   0.94116   0.97891   0.98334   
Original: 0.86519   0.94464   0.95239   0.97414   0.98774   

DEFINITIONS:
Accuracy is simply the proportion of classifications which are correct. It is directly
provided by the "getModelResults" function, as the "tensorflowResultAccuracy" value.

Confidence is the average predictive strength of the model towards the correct category
for each test recording, regardless of whether or not the model actually selected this
category. It is derived from the "tensorflowPredictionResult" value, also provided by the
"getModelResults" function.

Correct Confidence is the model's average predictive strength across classifications which
turned out to be correctly chosen. For this reason, note that the Correct Confidence score
is necessarily greater than the Confidence score for any given dataset or model.